{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a65d7387",
   "metadata": {},
   "source": [
    "# Transfer Learning on google/vit-base-patch16-224\n",
    "- From HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37051e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --quiet evaluate transformers # For training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e36cdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoImageProcessor, ViTForImageClassification\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d0b190",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ffd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"AaronLoera/Qr_Classifier\") # Whenever we upload to hub\n",
    "dataset\n",
    "\n",
    "labels = ...#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2abf1e2",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf71171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image processor\n",
    "\"\"\" \n",
    "Prepares input features for vision models and post processing their outputs by \n",
    "    transformations such as resizing, normalization, and conversion to PyTorch \n",
    "    and Numpy tensors.\n",
    "\"\"\"\n",
    "processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "processor\n",
    "\n",
    "label2id = ... # Fill in with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function prepares a batch of raw image data and labels so they can be fed into a model.\n",
    "\"\"\"\n",
    "def transforms(batch):\n",
    "    batch['image'] = [Image.open(io.BytesIO(x['bytes'])).convert('RGB') for x in batch['image']]\n",
    "    inputs = processor(batch['image'],return_tensors='pt')\n",
    "    inputs['labels']=[label2id[y] for y in batch['label']]\n",
    "    return inputs\n",
    "\n",
    "\"\"\"\n",
    "This function takes a list of inputs dictionaries (from transforms) and stacks \n",
    "    them into batch tensors.\n",
    "\"\"\"\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b7587",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b873891",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute evaluation metrics for model predictions using the Hugging Face\n",
    "    `evaluate` library.\n",
    "\"\"\"\n",
    "accuracy = evaluate.load('accuracy')\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits,axis=1)\n",
    "    score = accuracy.compute(predictions=predictions, references=labels)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e57ace",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28eec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    num_labels = 2,\n",
    "    id2label = ...,\n",
    "    label2id = ..., \n",
    "    ignore_mismatched_sizes=True\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708bd08b",
   "metadata": {},
   "source": [
    "### Freezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze 85,827,109 params\n",
    "for name,p in model.named_parameters():\n",
    "    if not name.startswith('classifier'):\n",
    "        p.requires_grad = False\n",
    "\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "trainable_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "\n",
    "print(f\"{num_params = :,} | {trainable_params = :,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081a4ea",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de23d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments and train\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit-base-qr-classifier\",\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=.0001,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=True,\n",
    "    report_to='none',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=...,\n",
    "    eval_dataset=...,\n",
    "    tokenizer=processor\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1515b89",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
